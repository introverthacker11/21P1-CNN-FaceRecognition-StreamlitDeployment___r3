# -*- coding: utf-8 -*-
"""21P1-CNN-Face Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wl2apFNSCDld5IXjVctIeCd6oHSuGedF
"""

import numpy as np
from sklearn.datasets import fetch_lfw_people

df = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
df

type(df)

df.data

df.images

df.target

df.target_names

df.data.shape, df.images.shape, df.target.shape, df.target_names.shape

df.data[0], len(df.data[0]), df.images[0], len(df.images[0])

"""<br>

---

<br>

### Each row in the data array corresponds to one image, and each value in that row represents a pixel's intensity (normalized between 0 and 1).

#### Since the shape is (1288, 1850):
- 1288 → Total number of images.
- 1850 → Number of pixel values per image (which means each image has 1850 pixels).

#### Example:
- Look at the first row of data: [0.9973857 , 0.99607843, 0.9921568 , ..., 0.38169935, 0.38823533, 0.3803922 ] which is representing 1st image of dataset.
- Here, the values "0.9973857, 0.99607843... 0.3803922" are representing the pixels of 1st image.
- i.e: 1st pixel is 99.73857% gray, 2nd is 99.607843% gray and last pixel is 38.03922% gray.

---

<br>

### Each double bracket [[ ... ]] represents a single image, which is a 2D matrix (height × width).
### From the shape (1288, 50, 37), we can see that:
- Each image has 50 rows (height).
- Each row has 37 values (width, i.e., columns).
- Each double bracket [[ ... ]] contains 50 rows, where each row has 37 values.
"""

np.where(df.target_names == "George W Bush")

import numpy as np

# Find index of "George W Bush" in target_names
bush_index = np.where(df.target_names == "George W Bush")[0][0]

# Get all images of George W Bush
bush_images = df.images[df.target == bush_index]
print("Bush images shape:", bush_images)

import matplotlib.pyplot as plt

df.target_names

for label, name in enumerate(df.target_names):
    print(f"Label: {label}, Name: {name}")

ask = input("\nEnter label for name: ")
num = int(input("Enter number of images: "))

image_label = df.images[df.target == int(ask)]

for i in range(min(len(image_label), num)):
    print(f"\nShowing image {i+1} of {df.target_names[int(ask)]}")
    plt.imshow(image_label[i], cmap='gray')
    plt.axis('off')
    plt.show()

image = df.images[0]

plt.imshow(image, cmap='gray')
plt.axis('off')
plt.show()

image = df.data[4].reshape((50,37))

plt.imshow(image, cmap='gray')
plt.axis('off')
plt.show()

x, y = df.images, df.target

target_names = df.target_names

print(x.shape)
x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)
x.shape

from tensorflow.keras.utils import to_categorical

cat_y = to_categorical(y)
cat_y, cat_y[0], len(cat_y[0])

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, cat_y, test_size = 0.2, random_state = 42)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(50, 37, 1)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    #Dropout(0.5),
    Dense(len(target_names), activation='softmax')  # Output layer
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

history = model.fit(x_train, y_train, epochs = 20, batch_size = 32, validation_data = (x_test, y_test))
history

history.history

test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_acc * 100:.3f} %")

y_pred = model.predict(x_test)
y_pred

y_pred = np.argmax(y_pred, axis = 1)
y_true = np.argmax(y_test, axis = 1)

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_true, y_pred, target_names = target_names))

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

import numpy as np

img = x_test[0]

img = np.expand_dims(img, axis=0)

prediction = model.predict(img)

print("Raw prediction (probabilities):", prediction)
print("Predicted class:", np.argmax(prediction))
print("True label:", y_test[0])

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

def predict_face_from_dataset(index):
    img = x_test[index]

    img_expanded = np.expand_dims(img, axis=0)

    prediction = model.predict(img_expanded)
    predicted_class = np.argmax(prediction)
    predicted_name = target_names[predicted_class]

    plt.imshow(img.squeeze(), cmap="gray")
    plt.title(f"Predicted: {predicted_name}")
    plt.axis("off")
    plt.show()

predict_face_from_dataset(7)

y_test, len(y_test), y_test[0], np.argmax(y_test, axis = 1)

y_pred, len(y_pred), y_pred[0]

np.argmax(y_test,axis = 1), y_pred

import pandas as pd

comp = pd.DataFrame({'y_test': np.argmax(y_test, axis = 1), 'y_pred': y_pred})
comp

difference = difference[difference['y_test'] != difference['y_pred']]
difference

len(comp), len(difference), len(comp) - len(difference)

saved_model = model.save("21P-CNN-Face Recognition.keras")

from keras.models import load_model

loded_saved_model = load_model("21P-CNN-Face Recognition.keras")

np.argmax(loded_saved_model.predict(x_test), axis = 1)

target_names = df.target_names

import pickle

with open("class_names.pkl", "wb") as f:
    pickle.dump(target_names, f)

import pickle

with open("class_names.pkl", "rb") as f:
    class_names = pickle.load(f)

class_names